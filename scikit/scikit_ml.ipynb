{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "18dbc51c-4ec6-4840-bff2-1ee6af1f2502",
          "showTitle": false,
          "title": ""
        },
        "id": "H3yw69R_b21b"
      },
      "source": [
        "# Problem definition\n",
        "\n",
        "In order to evaluate PySpark framework, we will apply the same workflow performed by it, but with scikit-learn, using a local processor, without paralel computation.\n",
        "\n",
        "The problem is a classification, based on flights informations from North America. The dataset used here is the same applied on Spark, and is available in Databricks datasets. It contains 1,391,578 rows, 5 columns and has no null values.\n",
        "\n",
        "Our workflow will consist of feature engineering, cross-validation, hyperparameter tuning and simple versus ensemble model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wMXZWH9Mb211"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "47deb2ac-3266-44ac-8c28-5f1077e135d0",
          "showTitle": false,
          "title": ""
        },
        "id": "08upD0xGb215"
      },
      "source": [
        "# 1. Feature Engineering\n",
        "\n",
        "The main difference between scikit-learn and PySpark Machine Learning library, is that Spark requires one vector containing all features, represented in sparse format. This is not necessary here, we separate the data between X and y, with X being a dataframe with all columns as features.\n",
        "\n",
        "We still perform the feature engineering, applying the same modifications made to Spark.<br>\n",
        "We will generate the target variable y, corresponding to delayed flights.<br>\n",
        "Next we will transform the date column into readable datetime format and bucketize it into intervals of 3 hours along 24 hours.<br>\n",
        "After we will implement one-hot encoder to the data.<br>\n",
        "And finally we will also apply scaler to the numerical feature distance.\n",
        "\n",
        "## 1.1. Target variable y\n",
        "\n",
        "The Federal Aviation Administration (FAA) considers a flight to be \"delayed\" when it arrives 15 minutes or more after its scheduled time. Thus we will be creating the target variable y, accordingly to FAA definition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "35138769-14a8-4701-be00-b3f9fc8fa0c0",
          "showTitle": false,
          "title": ""
        },
        "id": "WSHJ8rReb216"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('flights.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "dd9b474c-6e4a-4f7f-9920-328896cad401",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYs9BCC5b218",
        "outputId": "ba041ff6-f770-4494-92e3-41c04efd937c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "False    1077104\n",
              "True      314474\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df = data.copy()\n",
        "df['label'] = np.where(df['delay'] >= 15, True, False)\n",
        "df.value_counts('label')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "e97ed5c8-c1e6-45aa-b682-ea623abf98b8",
          "showTitle": false,
          "title": ""
        },
        "id": "-HS9TWL8b22A"
      },
      "source": [
        "We can see that the data is unbalanced, having 3 times more non delayed flights.<br>\n",
        "However we will work with the data without changing its distribution, in order to evaluate both models performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "ef579115-9090-4cbe-93e2-8009a754d11a",
          "showTitle": false,
          "title": ""
        },
        "id": "8QjIh74mb22B"
      },
      "outputs": [],
      "source": [
        "# Transform boolean into numerical\n",
        "df['label'] = df['label'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "18352f9f-4bd8-4d2e-a7b3-77b8977fcb0a",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "odftP13ob22C",
        "outputId": "d53603e9-42fb-4dd2-ce08-4b87e5050aae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            date  delay  distance origin destination  label\n",
              "0        1011245      6       602    ABE         ATL      0\n",
              "1        1020600     -8       369    ABE         DTW      0\n",
              "2        1021245     -2       602    ABE         ATL      0\n",
              "3        1020605     -4       602    ABE         ATL      0\n",
              "4        1031245     -4       602    ABE         ATL      0\n",
              "...          ...    ...       ...    ...         ...    ...\n",
              "1391573  3310623    -10       139    YUM         PHX      0\n",
              "1391574  3311505     -4       139    YUM         PHX      0\n",
              "1391575  3311846      0       206    YUM         LAX      0\n",
              "1391576  3310500     -7       206    YUM         LAX      0\n",
              "1391577  3311432      6       206    YUM         LAX      0\n",
              "\n",
              "[1391578 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cded879f-bf19-4b2a-be0c-c2ae652730df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>delay</th>\n",
              "      <th>distance</th>\n",
              "      <th>origin</th>\n",
              "      <th>destination</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1011245</td>\n",
              "      <td>6</td>\n",
              "      <td>602</td>\n",
              "      <td>ABE</td>\n",
              "      <td>ATL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1020600</td>\n",
              "      <td>-8</td>\n",
              "      <td>369</td>\n",
              "      <td>ABE</td>\n",
              "      <td>DTW</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1021245</td>\n",
              "      <td>-2</td>\n",
              "      <td>602</td>\n",
              "      <td>ABE</td>\n",
              "      <td>ATL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1020605</td>\n",
              "      <td>-4</td>\n",
              "      <td>602</td>\n",
              "      <td>ABE</td>\n",
              "      <td>ATL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1031245</td>\n",
              "      <td>-4</td>\n",
              "      <td>602</td>\n",
              "      <td>ABE</td>\n",
              "      <td>ATL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1391573</th>\n",
              "      <td>3310623</td>\n",
              "      <td>-10</td>\n",
              "      <td>139</td>\n",
              "      <td>YUM</td>\n",
              "      <td>PHX</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1391574</th>\n",
              "      <td>3311505</td>\n",
              "      <td>-4</td>\n",
              "      <td>139</td>\n",
              "      <td>YUM</td>\n",
              "      <td>PHX</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1391575</th>\n",
              "      <td>3311846</td>\n",
              "      <td>0</td>\n",
              "      <td>206</td>\n",
              "      <td>YUM</td>\n",
              "      <td>LAX</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1391576</th>\n",
              "      <td>3310500</td>\n",
              "      <td>-7</td>\n",
              "      <td>206</td>\n",
              "      <td>YUM</td>\n",
              "      <td>LAX</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1391577</th>\n",
              "      <td>3311432</td>\n",
              "      <td>6</td>\n",
              "      <td>206</td>\n",
              "      <td>YUM</td>\n",
              "      <td>LAX</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1391578 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cded879f-bf19-4b2a-be0c-c2ae652730df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cded879f-bf19-4b2a-be0c-c2ae652730df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cded879f-bf19-4b2a-be0c-c2ae652730df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "be939300-b63e-4488-a061-351e119d69e2",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZSo-LC0b22D",
        "outputId": "81d3821c-c088-4c86-f771-20121f176cd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data contain 1391578 records.\n"
          ]
        }
      ],
      "source": [
        "# Get number of records\n",
        "print(\"The data contain %d records.\" % df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "5c5e0694-91cd-4094-903f-68a2463eeae7",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJccizJmb22E",
        "outputId": "26ad924f-5981-482a-ba03-8fe4cf3acc6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1391578 entries, 0 to 1391577\n",
            "Data columns (total 6 columns):\n",
            " #   Column       Non-Null Count    Dtype \n",
            "---  ------       --------------    ----- \n",
            " 0   date         1391578 non-null  int64 \n",
            " 1   delay        1391578 non-null  int64 \n",
            " 2   distance     1391578 non-null  int64 \n",
            " 3   origin       1391578 non-null  object\n",
            " 4   destination  1391578 non-null  object\n",
            " 5   label        1391578 non-null  int64 \n",
            "dtypes: int64(4), object(2)\n",
            "memory usage: 63.7+ MB\n"
          ]
        }
      ],
      "source": [
        "# Print DataFrame structure\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "e075e48e-bdbd-44d4-b8b5-d3d58d181fbc",
          "showTitle": false,
          "title": ""
        },
        "id": "DhjvN6pLb22F"
      },
      "source": [
        "## 1.2. Column departure\n",
        "\n",
        "We will first convert the time column into string, so next we can convert it into timestamp.<br>\n",
        "Then we will apply the bucketizer step for intervals of 3 hours."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "d9a048ae-d48a-4839-996a-8f7b50849017",
          "showTitle": false,
          "title": ""
        },
        "id": "ykOJywkbb22F"
      },
      "outputs": [],
      "source": [
        "# Transform string to timestamp\n",
        "df['departure'] = '20140' + df['date'].astype(str)\n",
        "df['departure'] = pd.to_datetime(df['departure'], format='%Y%m%d%H%M')\n",
        "\n",
        "# Get hour from departure time\n",
        "df['hour'] = df['departure'].dt.hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "b03beb80-b751-405e-b083-5a880d1a2a0f",
          "showTitle": false,
          "title": ""
        },
        "id": "uUaeMbumb22G"
      },
      "outputs": [],
      "source": [
        "# Bucketizing departure time\n",
        "ranges = [0,3,6,9,12,15,18,21,np.inf]\n",
        "group_names = ['0-3h', '3-6h', '6-9h', '9-12h', '12-15h', '15-18h', '18-21h', '21-24h']\n",
        "df['departure_bucket'] = pd.cut(df['hour'], bins=ranges, labels=group_names)\n",
        "df['departure_bucket'] = df['departure_bucket'].astype('category')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "02aa0306-ead8-4fee-8816-2fdbbb7eecdc",
          "showTitle": false,
          "title": ""
        },
        "id": "YfqQl7bfb22H"
      },
      "source": [
        "## 1.3. Categorical features\n",
        "\n",
        "The categorical features origin and destination contain the IATA code for airports of North America. Since there are around 300 different airports in the dataset, we will replace them by their state, reducing to a total of 65 states.\n",
        "\n",
        "In order to do this, we will need to import a second database, containing the airports informations. We will perform a join between the two tables, to get the corresponding states.\n",
        "\n",
        "Finally we will apply one-hot encoder to the states."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PF9ilFUGb22H"
      },
      "outputs": [],
      "source": [
        "df_air = pd.read_csv('airport_codes_na.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "d2b81aaa-2b5b-465d-abb7-fea07e0e3095",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "6s9XcoTyb22I",
        "outputId": "21e9432d-2b5f-468b-a7de-19587b646a59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            City State Country IATA\n",
              "0     Abbotsford    BC  Canada  YXX\n",
              "1       Aberdeen    SD     USA  ABR\n",
              "2        Abilene    TX     USA  ABI\n",
              "3          Akron    OH     USA  CAK\n",
              "4        Alamosa    CO     USA  ALS\n",
              "..           ...   ...     ...  ...\n",
              "521     Wrangell    AK     USA  WRG\n",
              "522       Yakima    WA     USA  YKM\n",
              "523      Yakutat    AK     USA  YAK\n",
              "524  Yellowknife   NWT  Canada  YZF\n",
              "525         Yuma    AZ     USA  YUM\n",
              "\n",
              "[526 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3e7cd89-f44f-47bb-9b62-db2be3824903\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "      <th>Country</th>\n",
              "      <th>IATA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>BC</td>\n",
              "      <td>Canada</td>\n",
              "      <td>YXX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Aberdeen</td>\n",
              "      <td>SD</td>\n",
              "      <td>USA</td>\n",
              "      <td>ABR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abilene</td>\n",
              "      <td>TX</td>\n",
              "      <td>USA</td>\n",
              "      <td>ABI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Akron</td>\n",
              "      <td>OH</td>\n",
              "      <td>USA</td>\n",
              "      <td>CAK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alamosa</td>\n",
              "      <td>CO</td>\n",
              "      <td>USA</td>\n",
              "      <td>ALS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>Wrangell</td>\n",
              "      <td>AK</td>\n",
              "      <td>USA</td>\n",
              "      <td>WRG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>Yakima</td>\n",
              "      <td>WA</td>\n",
              "      <td>USA</td>\n",
              "      <td>YKM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>Yakutat</td>\n",
              "      <td>AK</td>\n",
              "      <td>USA</td>\n",
              "      <td>YAK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>Yellowknife</td>\n",
              "      <td>NWT</td>\n",
              "      <td>Canada</td>\n",
              "      <td>YZF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>Yuma</td>\n",
              "      <td>AZ</td>\n",
              "      <td>USA</td>\n",
              "      <td>YUM</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>526 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3e7cd89-f44f-47bb-9b62-db2be3824903')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3e7cd89-f44f-47bb-9b62-db2be3824903 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3e7cd89-f44f-47bb-9b62-db2be3824903');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df_air"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sTVjMSYjb22I"
      },
      "outputs": [],
      "source": [
        "# Join on origin\n",
        "df_origin = df_air[['IATA', 'State']]\n",
        "df_origin.columns = ['origin', 'origin_state']\n",
        "df = df.merge(df_origin, on='origin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Mtvrnux1b22J"
      },
      "outputs": [],
      "source": [
        "# Join on destination\n",
        "df_dest = df_air[['IATA', 'State']]\n",
        "df_dest.columns = ['destination', 'dest_state']\n",
        "df = df.merge(df_dest, on='destination')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lTJtrHZUb22M"
      },
      "outputs": [],
      "source": [
        "# Select only feature columns\n",
        "df = df[['distance', 'label', 'departure_bucket', 'origin_state', 'dest_state']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nRVd-XdZb22M"
      },
      "outputs": [],
      "source": [
        "# One-hot encoder\n",
        "df = pd.get_dummies(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "8a13c412-a616-4ff9-989c-7980800e9ff8",
          "showTitle": false,
          "title": ""
        },
        "id": "F65xVdH8b22N"
      },
      "source": [
        "## 1.4. Train-test split\n",
        "\n",
        "Before applying any fitting or prediction, we will split the data into training and test sets. This will ensure that data leakage does not occur during all process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "39f0f636-900c-40dc-b435-9fee84b98427",
          "showTitle": false,
          "title": ""
        },
        "id": "p-irQVoRb22O"
      },
      "outputs": [],
      "source": [
        "# Split the data\n",
        "X = df.drop('label', axis=1)\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5. Distance scaler\n",
        "\n",
        "This step was not present in Spark workflow, but here we will also apply a scaler to the numerical feature distance."
      ],
      "metadata": {
        "id": "BxIEuJcWGiPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train['distance'].values.reshape(-1,1))\n",
        "\n",
        "X_train['distance'] = scaler.transform(X_train['distance'].values.reshape(-1,1))\n",
        "X_test['distance'] = scaler.transform(X_test['distance'].values.reshape(-1,1))"
      ],
      "metadata": {
        "id": "EYoL3iwqGjL1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KVIQfeMb22P"
      },
      "source": [
        "# 2. Models\n",
        "\n",
        "We will apply the same two classification models applied to Spark: logistic regression and ensemble Random Forest.<br>\n",
        "Being more simple, Logistic regression will be used as baseline model.<br>\n",
        "We will perform hyperparameter tuning on them, with grid-search cross-validation and evaluate the best model on the test set.<br>\n",
        "We will apply two evaluations for both models: ROC-AUC and Confusion Matrix.<br>\n",
        "The difference here to Spark is that we will declare first the models and their grid search, in order to perform grid-search cross-validation later. Different from Spark, we will not apply pipelines here.\n",
        "\n",
        "## 2.1. Evaluators\n",
        "\n",
        "We don't need to declare both evaluators roc_auc and confusion matrix because they are already implemented as functions by scikit-learn.\n",
        "\n",
        "## 2.2. Logistic Regression\n",
        "\n",
        "The Logistic Regression will be our baseline model, for comparison.<br>\n",
        "For its hyperparameters we will search for 'C' wich is the inverse of regularization strength λ and 'penalty' which is the norm of Regularization α (L1/L2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "srW0VkDlb22T"
      },
      "outputs": [],
      "source": [
        "# Create Logistic Regression model\n",
        "lr = LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kzfxCIpAb22T"
      },
      "outputs": [],
      "source": [
        "# Make a grid for grid-search\n",
        "params_lr = {'C': [1, .1, .01],\n",
        "             'penalty': ['l2', 'none']}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAp1yCz8b22T"
      },
      "source": [
        "## 2.3. Ensemble Random Forest\n",
        "\n",
        "We will declare a Random Forest model and search for its best hyperparameters, through grid-search cross-validation.<br>\n",
        "For its hyperparameters we will search for 'max_features' wich is the number of features to consider and 'max_depth' which is the maximum depth of the tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eEes_xjzb22U"
      },
      "outputs": [],
      "source": [
        "# Create Random Forest model\n",
        "rf = RandomForestClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dn-vRlolb22U"
      },
      "outputs": [],
      "source": [
        "# Make a grid for grid-search\n",
        "params_rf = {'max_features': [None, 0.3, 'sqrt', 'log2'],\n",
        "             'max_depth': [2, 5, 10]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67EoMyCbb22X"
      },
      "source": [
        "# 3. Logistic Regression Cross-Validation\n",
        "\n",
        "Now through grid-search cross-validation, we may search for the best hyperparameters, on the training set, and use the best model to predict the test set, in order to evaluate the results.\n",
        "\n",
        "## 3.1. Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Vi5WIKTpb22Z"
      },
      "outputs": [],
      "source": [
        "# Create the CrossValidator\n",
        "cv_lr = GridSearchCV(estimator=lr,\n",
        "                     param_grid=params_lr,\n",
        "                     cv=3,\n",
        "                     scoring='roc_auc',\n",
        "                     verbose=1,\n",
        "                     n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWmiOiXAb22Z",
        "outputId": "88799348-582e-4117-a097-e1ae0fd0e100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation training with Logistic Regression took around 4.65 min.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Train the model and time it\n",
        "t_start = time.time()\n",
        "cv_lr.fit(X_train, y_train)\n",
        "t_total = time.time() - t_start\n",
        "print('Cross-validation training with Logistic Regression took around {:.2f} min.'.format(t_total/60))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypnqJFevb22a"
      },
      "source": [
        "## 3.2. Cross-Validation Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUQAh-q4b22a",
        "outputId": "b754a699-e58c-42ff-f7bd-097b4f4a6157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1)\n"
          ]
        }
      ],
      "source": [
        "# Extract the best model\n",
        "best_lr = cv_lr.best_estimator_\n",
        "\n",
        "# Print best_lr\n",
        "print(best_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjciMlgCb22b",
        "outputId": "5e568b36-2717-4d1f-c4c3-d5de563ca258"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1, 'penalty': 'l2'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "cv_lr.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUWewpSXb22b"
      },
      "source": [
        "## 3.3. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_9jngLv7b22c"
      },
      "outputs": [],
      "source": [
        "predictions_lr = best_lr.predict(X_test)\n",
        "pred_lr_proba = best_lr.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nFGDnG0b22c",
        "outputId": "8801bcb5-e881-4fc1-bbd5-1663707d5c1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roc_auc score:  0.651290281587436\n",
            "confusion matrix:\n",
            " [[315531     23]\n",
            " [ 92767     22]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      1.00      0.87    315554\n",
            "           1       0.49      0.00      0.00     92789\n",
            "\n",
            "    accuracy                           0.77    408343\n",
            "   macro avg       0.63      0.50      0.44    408343\n",
            "weighted avg       0.71      0.77      0.67    408343\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the predictions\n",
        "print('roc_auc score: ', roc_auc_score(y_test.values, pred_lr_proba[:,1]))\n",
        "\n",
        "print('confusion matrix:\\n', confusion_matrix(y_test.values, predictions_lr))\n",
        "print(classification_report(y_test.values, predictions_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzqw_3nib22d"
      },
      "source": [
        "# 4. Ensemble Random Forest Cross-Validation\n",
        "\n",
        "Now through grid-search cross-validation, we may search for the best hyperparameters, on the training set, and use the best model to predict the test set, in order to evaluate the results.\n",
        "\n",
        "## 4.1. Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "PshOodSeb22e"
      },
      "outputs": [],
      "source": [
        "# Create the CrossValidator\n",
        "cv_rf = GridSearchCV(estimator=rf,\n",
        "                     param_grid=params_rf,\n",
        "                     cv=3,\n",
        "                     scoring='roc_auc',\n",
        "                     verbose=1,\n",
        "                     n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZWy9oU6b22e",
        "outputId": "ea6efaaf-2b6b-4e32-eeb5-f301a79d6175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "Cross-validation training with Random Forest took around 45.65 min.\n"
          ]
        }
      ],
      "source": [
        "# Train the model and time it\n",
        "t_start = time.time()\n",
        "cv_rf.fit(X_train, y_train)\n",
        "t_total = time.time() - t_start\n",
        "print('Cross-validation training with Random Forest took around {:.2f} min.'.format(t_total/60))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y98c-Lqb22f"
      },
      "source": [
        "## 4.2. Cross-Validation Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK0hLOzDb22f",
        "outputId": "903e3e50-966b-4a34-9672-78a437d460e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_depth=10, max_features='sqrt')\n"
          ]
        }
      ],
      "source": [
        "# Extract the best model\n",
        "best_rf = cv_rf.best_estimator_\n",
        "\n",
        "# Print best_rf\n",
        "print(best_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIlMTyLgb22f",
        "outputId": "38ebb0ac-8658-453f-83c7-d90380b07376"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 10, 'max_features': 'sqrt'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "cv_rf.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo7LTyMXb22g"
      },
      "source": [
        "## 4.3. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1xswBcD9b22g"
      },
      "outputs": [],
      "source": [
        "predictions_rf = best_rf.predict(X_test)\n",
        "pred_rf_proba = best_rf.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2vq4zoKb22g",
        "outputId": "6cbf8a86-2c30-4537-fb14-2b4b4e3da5b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roc_auc score:  0.6537192485778919\n",
            "confusion matrix:\n",
            " [[315554      0]\n",
            " [ 92789      0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      1.00      0.87    315554\n",
            "           1       0.00      0.00      0.00     92789\n",
            "\n",
            "    accuracy                           0.77    408343\n",
            "   macro avg       0.39      0.50      0.44    408343\n",
            "weighted avg       0.60      0.77      0.67    408343\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the predictions\n",
        "print('roc_auc score: ', roc_auc_score(y_test.values, pred_rf_proba[:,1]))\n",
        "\n",
        "print('confusion matrix:\\n', confusion_matrix(y_test.values, predictions_rf))\n",
        "print(classification_report(y_test.values, predictions_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "1e301e2d-c31e-4c6a-8a84-4b68ff394594",
          "showTitle": false,
          "title": ""
        },
        "id": "NFfHvnJsb22h"
      },
      "source": [
        "# 5. Conclusions\n",
        "\n",
        "Spark is optimized for big data handling. Therefore, it may take more time to deal with small data.<br>\n",
        "Comparing scikit-learn and Spark performance, we see that Logistic Regression grid-search was faster in scikit-learn, with around 5 min.<br>\n",
        "Random Forest, however, is impacted by the curse of dimensionality. Here we can see that Spark took around 22 min to perform the grid-search while scikit-learn took around 45 min.<br>\n",
        "While our data had around 1.4 million rows (30 MB), it is still very small compared to big data, where Spark really shine.\n",
        "\n",
        "|Framework|Model|Cross-Validation training time|\n",
        "|--|--|--|\n",
        "|Spark|Logistic Regression|8 min|\n",
        "|scikit-learn|Logistic Regression|5 min|\n",
        "|Spark|Random Forest|22 min|\n",
        "|scikit-learn|Random Forest|45 min|\n",
        "\n",
        "Analyzing both models evaluation, we can see that both models performed poorly, heavily impacted by data unbalance. Here Random Forest actually turned out the worst model, because it predicted 0 (not delay) for all cases, still achieving a high accuracy and roc auc score.\n",
        "\n",
        "|Metric|Logistic Regression|Random Forest|\n",
        "|--|--|--|\n",
        "|ROC AUC|0.6513|0.6537|\n",
        "|Accuracy|0.77|0.77|\n",
        "|Precision|0.49|0.00|\n",
        "|Recall|0.00|0.00|\n",
        "|F1-Score|0.00|0.00|\n",
        "\n",
        "Oversampling or undersampling and other metrics would be proper steps, but we tried to reproduce only similar steps between both frameworks, in order to evaluate both performance.\n",
        "\n",
        "We conclude here that Spark framework is more recommended for big data. Its parallel processing guarantees less processing time when the data escalates. Also both frameworks may perform differently depending on configurations setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "b2e07084-4f0d-45de-84d3-6cd0b7d29bab",
          "showTitle": false,
          "title": ""
        },
        "id": "Dh97u9Lkb22i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "mostRecentlyExecutedCommandWithImplicitDF": {
          "commandId": -1,
          "dataframes": [
            "_sqldf"
          ]
        },
        "pythonIndentUnit": 2
      },
      "notebookName": "pyspark_ml",
      "notebookOrigID": 68202399794172,
      "widgets": {}
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}